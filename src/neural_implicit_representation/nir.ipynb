{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb31559a-605d-4e92-a836-b1dbf2ee8147",
   "metadata": {},
   "source": [
    "# Neural Implicit Representation\n",
    "\n",
    "Faisal Qureshi     \n",
    "faisal.qureshi@ontariotechu.ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe5dcc9-9c65-4ae4-864b-c7a8168d4823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4503378-c494-49f7-a74d-10bfaedd4810",
   "metadata": {},
   "source": [
    "## Picking an MNIST digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b6ea11-5e71-4585-a6d2-4a4f7072a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "\n",
    "def pick_mnist_image(idx=0, download=False):\n",
    "    data = tv.datasets.MNIST(root='../../data', download=download)\n",
    "    image = np.array(data[idx][0])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e153b-b981-44f7-a48d-2bb9987bcbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pick_mnist_image(idx=0, download=False)\n",
    "h, w = image.shape\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title(f'{w}x{h}')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(image, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca1862-e0df-40fe-b5dd-a5a1a555b1f0",
   "metadata": {},
   "source": [
    "## Pixel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0d78c4-70f8-4b2d-a1a8-aea588fbacdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # Need for positional_encoding.py\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as tdata\n",
    "import positional_encoding as pe\n",
    "\n",
    "class NimDataset(tdata.Dataset):\n",
    "    def __init__(self, image, pos_enc_dim=8):\n",
    "        self.image = image / 255.\n",
    "        self.pos, self.enc_x, self.enc_y = self.construct_positional_encoding(self.image, pos_enc_dim=pos_enc_dim)\n",
    "        self.n = len(self.pos)\n",
    "        \n",
    "    @staticmethod\n",
    "    def construct_positional_encoding(image, pos_enc_dim):\n",
    "        h, w = image.shape\n",
    "        x, y = np.arange(w), np.arange(h)\n",
    "        xx, yy = np.meshgrid(x, y)\n",
    "        pos = np.stack([xx, yy, image], axis=2).reshape(-1, 3)\n",
    "        enc_x = pe.positional_encoding(x, pos_enc_dim)\n",
    "        enc_y = pe.positional_encoding(y, pos_enc_dim)\n",
    "        return pos, enc_x, enc_y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.pos[idx, 0]\n",
    "        y = self.pos[idx, 1]\n",
    "        e_x = self.enc_x[int(x)]\n",
    "        e_y = self.enc_y[int(y)]\n",
    "        return {\n",
    "            'pos': torch.Tensor(np.hstack((e_x, e_y))),\n",
    "            'c': torch.Tensor(self.pos[idx, 2:])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a13af5-30ea-4a15-9838-87665740cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NimDataset(image, 8)\n",
    "dataset[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40ee525-26d5-4ea4-b7a8-6eb975c8f7ee",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50ac4a-f314-4241-b190-df2402429aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nir(torch.nn.Module):\n",
    "    def __init__(self, h, w, pos_enc_dim, output_dim):\n",
    "        super(Nir, self).__init__()\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(pos_enc_dim*2, 32)\n",
    "        self.linear2 = torch.nn.Linear(32, 32)\n",
    "        self.linear3 = torch.nn.Linear(32, 16)        \n",
    "        self.linear4 = torch.nn.Linear(16, output_dim)\n",
    "        \n",
    "        self.h, self.w, self.pos_enc_dim = h, w, pos_enc_dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sin(self.linear1(x))\n",
    "        x = torch.sin(self.linear2(x))\n",
    "        x = torch.sin(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f932f1f1-7f44-498a-a11c-d8222954bb16",
   "metadata": {},
   "source": [
    "## DataLoader and compute device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758afdaa-5009-4869-ba1c-b4db9125db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "training_data = NimDataset(image, 8)\n",
    "train_dataloader = DataLoader(training_data, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee8ebb5-fe11-46d8-b2b1-e65c317a421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04695678-0b8f-4fac-a2db-a69609879fda",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d044903c-c649-4a84-b48e-4cf82c7a58b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "model = Nir(28, 28, 8, 1).to(device)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    loss_epoch = 0.0\n",
    "    cnts = 0\n",
    "    for _, data in enumerate(train_dataloader):\n",
    "        inputs = data['pos'].to(device)\n",
    "        labels = data['c'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)    \n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        cnts += 1\n",
    "        loss_epoch += loss.cpu().item()\n",
    "        \n",
    "    loss_epoch /= cnts\n",
    "    writer.add_scalar('Loss/train', loss, epoch)\n",
    "        \n",
    "    if epoch % 1000 == 0 or epoch == num_epochs-1:\n",
    "        print(f'epoch = {epoch}: loss = {loss_epoch}')\n",
    "        \n",
    "#torch.save(model.state_dict(), './nir.pts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91fc29b-3a1e-44b4-8a52-2c755b12f08d",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57411bff-d714-4053-8df3-6a439317094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_image(model):\n",
    "    h, w, pos_enc_dim = model.h, model.w, model.pos_enc_dim\n",
    "    \n",
    "    output_image = np.empty((h,w))\n",
    "    x, y = np.arange(w), np.arange(h)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    pos = np.stack([xx, yy], axis=2).reshape(-1, 2)\n",
    "\n",
    "    model.eval()\n",
    "    for i in range(pos.shape[0]):\n",
    "        x, y = pos[i, 0], pos[i, 1]\n",
    "        enc_x = pe.positional_encoding(x, pos_enc_dim)\n",
    "        enc_y = pe.positional_encoding(y, pos_enc_dim)\n",
    "        inputs = torch.Tensor(np.hstack((enc_x, enc_y))).unsqueeze(0).to(device)\n",
    "        c = model(inputs)\n",
    "        output_image[int(y)][int(x)] = c.detach().cpu()[0][0][0].numpy()\n",
    "    \n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35c393-f721-4b5e-8a1c-75d6b0d8deff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Nir(28, 28, 8, 1)\n",
    "model.load_state_dict(torch.load('./nir.pts'))\n",
    "model.to(device)\n",
    "\n",
    "output_image = reconstruct_image(model)\n",
    "h, w = output_image.shape\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(f'reconstructed {w}x{h}')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(output_image, cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(f'original {w}x{h}')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c370d64-3380-4334-8aec-1f5903927a9c",
   "metadata": {},
   "source": [
    "## Super-resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee4fd2-7797-4857-be7d-2557b0e9a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_image(model, new_h, new_w):\n",
    "    h, w, pos_enc_dim = model.h, model.w, model.pos_enc_dim\n",
    "    \n",
    "    output_image = np.empty((new_h,new_w))\n",
    "    x, y = np.linspace(0, w, new_w), np.linspace(0, h, new_h)    \n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    xx_, yy_ = np.meshgrid(np.arange(new_w), np.arange(new_h))\n",
    "    pos = np.stack([xx, yy, xx_, yy_], axis=2).reshape(-1, 4)\n",
    "\n",
    "    model.eval()\n",
    "    for i in range(pos.shape[0]):\n",
    "        x, y, x_, y_ = pos[i, 0], pos[i, 1], int(pos[i, 2]), int(pos[i, 3])\n",
    "        enc_x = pe.positional_encoding(x, pos_enc_dim)\n",
    "        enc_y = pe.positional_encoding(y, pos_enc_dim)\n",
    "        inputs = torch.Tensor(np.hstack((enc_x, enc_y))).unsqueeze(0).to(device)\n",
    "        c = model(inputs)        \n",
    "        output_image[y_][x_] = c.detach().cpu()[0][0][0].numpy()\n",
    "    \n",
    "    return output_image                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca57283-9eee-4cda-8b48-c6c5f3d396a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Nir(28, 28, 8, 1)\n",
    "model.load_state_dict(torch.load('./nir.pts'))\n",
    "model.to(device)\n",
    "\n",
    "new_h, new_w = 128, 128\n",
    "output_image = resample_image(model,new_h,new_w)\n",
    "h, w = 28, 28\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(f'reconstructed {new_h}x{new_w}')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(output_image, cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(f'original {h}x{w}')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb00952d-073b-4be5-b059-7351a9ebf922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
