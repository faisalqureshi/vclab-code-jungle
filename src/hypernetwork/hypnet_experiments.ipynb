{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84973f49-e7ac-41f4-a529-b06e921cad32",
   "metadata": {},
   "source": [
    "# Hypernetworks experiments\n",
    "\n",
    "Faisal Qureshi      \n",
    "faisal.qureshi@ontariotechu.ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd53f213-4cea-4f36-86c0-46a6a79ac2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242a713-db0a-4978-b18d-c43b2b7ad8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file1 = '../../data/imagecompression.info/rgb8bit/deer-small.ppm'\n",
    "image_in = np.array(Image.open(image_file1))\n",
    "image_file2 = '../../data/imagecompression.info/rgb8bit/deer-small-enhanced.ppm'\n",
    "image_out = np.array(Image.open(image_file2))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Input image')\n",
    "plt.imshow(image_in)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Enhanced image')\n",
    "plt.imshow(image_out);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23499bb4-b3d0-477c-9315-84ddddf3fa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "def lift(im):\n",
    "    \"\"\"lifts input (r,g,b) image to (r2,g2,b2,rg,rb,gb,r,g,b,1)\"\"\"\n",
    "    h, w, _ = im.shape\n",
    "    x = einops.rearrange(im, 'h w c -> c (h w)')\n",
    "    x = np.vstack((x**2, x[0,:]*x[1,:], x[0,:]*x[2,:], x[1,:]*x[2,:], x, np.ones(h*w)))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a46b7-4dd4-41ac-b7a8-beb1622d1cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_lifted = lift(image_in)\n",
    "print(im_lifted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4689bc2b-9258-4313-a4a8-e40609b7bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "einops.rearrange(im_lifted, 'c (h w) -> h w c', w=512).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cf241e-6d04-4d76-a3d5-95ac53436dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as tdata\n",
    "\n",
    "class PixData(tdata.Dataset):\n",
    "    def __init__(self, image_in, image_out):\n",
    "        \"\"\"Input and output images 8bit rgb images.\"\"\"\n",
    "        self.h, self.w, _ = image_in.shape\n",
    "        self.image_in = torch.Tensor(lift(image_in)/255.)\n",
    "        self.image_out = torch.Tensor(rearrange(image_out/255., 'h w c -> c (h w)'))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.h*self.w\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'data': self.image_in[:, idx],\n",
    "            'out': self.image_out[:, idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff6c7a-5d8d-4760-b105-1a2687a13958",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PixData(image_in, image_out)\n",
    "print(len(dataset))\n",
    "\n",
    "dataset[0]['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28e156-1ec1-4d9b-9256-68874988c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Correct(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Correct, self).__init__()\n",
    "        self.linear = torch.nn.Linear(10,3,bias=False)\n",
    "        print(self.linear.weight.shape)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        print(self.linear.weight)\n",
    "        self.linear.weight = torch.nn.Parameter(torch.zeros((3,10)))\n",
    "        print(self.linear.weight)\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683d426-725b-443f-9254-147a57c3bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Correct()\n",
    "c(rearrange(dataset[0]['data'], 'w -> () w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39f1292-9496-441f-a173-38772662419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as torch_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6ef09-bb7b-48ca-8fa8-4b7fe52ab277",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = torch_models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc09ecbd-0021-4575-9a0c-b1a094339b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0f2c8e-24de-4a14-8408-20ef8492f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in resnet18.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2271d05e-74c8-4e0d-8c7e-71be76a65ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dict(resnet18.named_parameters())\n",
    "x.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1143b-1970-4737-afb1-72d3a2d199f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file1 = '../../data/imagecompression.info/rgb8bit/deer-small.ppm'\n",
    "tmp = np.array(Image.open(image_file1).resize((224,224), Image.BILINEAR))\n",
    "print(tmp.shape)\n",
    "print(tmp.min(), tmp.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a6057f-c6f1-427c-bf86-cf97d2c74378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626e0753-15e0-4daa-8faf-239fdd995b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                      transforms.ToTensor(), \n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3f570e-162c-47c1-be2e-e461b7fb61ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data_transforms(Image.open(image_file1))\n",
    "print(tmp.shape)\n",
    "print(tmp.min(), tmp.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcccfc54-bca0-4244-be4b-23db12750789",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w, _ = tmp.shape\n",
    "print(h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6214b-d9e8-437f-b750-ac1fb638db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Test, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(3,5)\n",
    "        self.l2 = nn.Linear(5,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bebf74c-57d1-4887-9978-c127c50c8449",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Test() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b140d150-2f79-4c22-8979-fa76d4aa873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in t.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d34181-d376-4a73-aacf-eb6b59d88aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in t.named_parameters():\n",
    "    print(n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c7711-1ee0-420b-89c7-604d919dd976",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dict(t.named_parameters())\n",
    "x['l1.weight'].requires_grad = False\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257ad2e-d29b-4842-8a75-2ecdb25628da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Test2, self).__init__()\n",
    "        \n",
    "        self.b = Test()\n",
    "        for p in self.b.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "        print(self.b.l2)\n",
    "        self.b.l2 = nn.Linear(5,2)\n",
    "        \n",
    "        self.l3 = nn.Linear(4,4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae4eba9-6969-4465-9b34-cbc3b04db5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = Test2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520bd80-bd39-43b4-8d26-55364a508dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in t2.named_parameters():\n",
    "    print(n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08937395-cb55-43e7-96af-b9bb6b69f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([p for p in t2.parameters() if p.requires_grad == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506add6d-6090-44b3-8ca3-49bf364150bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
